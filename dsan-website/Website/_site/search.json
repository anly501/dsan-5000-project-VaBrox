[
  {
    "objectID": "Pages/Clustering.html",
    "href": "Pages/Clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "The feature data used for this analysis is from the Formula 1 race, which have features such as driver, constructor, circuit, the stops driver make in one race, their pit stop time, and their final positio in that race. All these features include almost factors that could affects the final position result for a driver.\nEach driver got differnt strategy of pit stop frequency and time in different races, predicting their final position would be an enormous workload, therefore, we need to get some basic informations about the relationship among those features that could affect the final position for a driver. By excluding the ‘position’ column from our clustering, we can infer which feature may correlate with dirver success and then help a certain driver to improve their position in a race in the following analysis."
  },
  {
    "objectID": "Pages/Clustering.html#k-means-clustering",
    "href": "Pages/Clustering.html#k-means-clustering",
    "title": "Clustering",
    "section": "K-Means Clustering",
    "text": "K-Means Clustering\nK-means is a method that used to classify a set of points into K distinct non-overlapping clusters where each point belongs to the cluster with the nearest mean. In general, if we want to split points on a paper into 3 K-means groups, we would iteritively try to put all nearby points into one group that all points in this group are sharing some same patterns. The iteration will continuing untile it finds the best cluster classification.\nMeanwhile, we could use the Elbow and Silhouette method to evaluate how well the cluster classification is. For example, we can use Elbow method to see where the improvments in grouping points start to diminish therefore find the optimal parameters or features that are suitable for our analysis. Also we can use Silhouette method to give a score on our clusters where higher score represents a well classified cluster.\n\nkmeans = KMeans(n_clusters = 6, random_state = 82)\nkmeans_labels = kmeans.fit_predict(scaled_data)\n\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn("
  },
  {
    "objectID": "Pages/Clustering.html#elbow-method",
    "href": "Pages/Clustering.html#elbow-method",
    "title": "Clustering",
    "section": "Elbow Method",
    "text": "Elbow Method\n\ninertia_values = []\nclusters_range = range(1, 11)\nfor n_clusters in clusters_range:\n    kmeans = KMeans(n_clusters = n_clusters, random_state = 27)\n    kmeans.fit(scaled_data)\n    inertia_values.append(kmeans.inertia_)\n\ndistortion_values = [inertia/len(scaled_data) for inertia in inertia_values]\ndf_inertia = pd.DataFrame({'Number of Clusters': clusters_range, 'Distortion': distortion_values, 'Inertia': inertia_values})\ndf_inertia\n\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nNumber of Clusters\nDistortion\nInertia\n\n\n\n\n0\n1\n6.000000\n28386.000000\n\n\n1\n2\n3.921984\n18554.906181\n\n\n2\n3\n3.051876\n14438.424935\n\n\n3\n4\n2.505540\n11853.710351\n\n\n4\n5\n2.161148\n10224.389887\n\n\n5\n6\n1.687112\n7981.726708\n\n\n6\n7\n1.424744\n6740.461687\n\n\n7\n8\n1.213436\n5740.763534\n\n\n8\n9\n1.058498\n5007.753693\n\n\n9\n10\n0.968158\n4580.355328\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(1, 2)\n\n# Distortion plot\nax[0].plot(df_inertia['Number of Clusters'], df_inertia['Distortion'], color = 'g')\nax[0].set_xlabel('Clusters')\nax[0].set_ylabel('Distortion')\nax[0].legend(handles = [plt.Line2D([0], [0], color = 'g', lw = 2, label = 'Distortion')],loc = 'best')\nax[0].grid(True)\n\n# Inertia plot\nax[1].plot(df_inertia['Number of Clusters'], df_inertia['Inertia'], color = 'r')\nax[1].set_xlabel('Clusters')\nax[1].set_ylabel('Inertia')\nax[1].legend(handles = [plt.Line2D([0], [0], color = 'r', lw = 2, label = 'Inertia')],loc = 'best')\nax[1].grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nThe result showed by the Elbow method is not clear and quite hard to tell where should cut from the clusters. Therefore, this method is assumptively not suitable for this dataset to use.\n\nSilhouette Method\n\nopt_labels = maximize_silhouette(clustering_df, algo = \"kmeans\", nmax = 6, i_plot = True)\nplt.show()\n\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/Users/kai/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n\n\nOPTIMAL PARAMETER = 4\n\n\n\n\n\nThe Silhouette method take 4 as the optimal parameter."
  },
  {
    "objectID": "Pages/Clustering.html#dbscan-clustering",
    "href": "Pages/Clustering.html#dbscan-clustering",
    "title": "Clustering",
    "section": "DBSCAN Clustering",
    "text": "DBSCAN Clustering\nDBSCAN Clustering is density based clustering method that use the point neighbor density to decide the cluster. Then this cluster will keep looking for points that have the similar neighbor density as itself. In the end, points that does not belong to any density cluster will considered as noise.\n\nopt_labels = maximize_silhouette(clustering_df, algo = \"dbscan\", nmax = 20, i_plot = True)\nplt.show()\n\nOPTIMAL PARAMETER = 4.75\n\n\n\n\n\nThe DBSCAN method takes 4.75 as the optimal parameter which is approaching the result of 4 from the Silhouette method"
  },
  {
    "objectID": "Pages/Clustering.html#hierarchical-clustering",
    "href": "Pages/Clustering.html#hierarchical-clustering",
    "title": "Clustering",
    "section": "Hierarchical Clustering",
    "text": "Hierarchical Clustering\nWe could consider the Hierarchical Clustering as a type of tree on some level that points are absorbed into a group gradually and therefore create a link in the way of a dendrogram diagram. We can look at the dendrogram to decide where to ‘cut’ the tree to get a good number of clusters\n\nopt_labels = maximize_silhouette(clustering_df, algo = \"ag\", nmax = 6, i_plot= True)\nplt.show()\n\nOPTIMAL PARAMETER = 4\n\n\n\n\n\n\nZ = linkage(clustering_df, method = 'ward')  # You can change 'ward' to other methods: 'single', 'complete', 'average', ...\n\n# Plot the dendrogram\nplt.figure(figsize = (25, 10))\nplt.title('Hierarchical Clustering Dendrogram')\nplt.xlabel('sample index')\ndn = dendrogram(Z)\nplt.show()"
  },
  {
    "objectID": "Pages/Feature selection for record data.html",
    "href": "Pages/Feature selection for record data.html",
    "title": "Feature Selection for Record Data",
    "section": "",
    "text": "## import libraries\nimport pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.datasets import load_iris\nfrom sklearn.metrics import accuracy_score\nimport random\nfrom sklearn.feature_selection import VarianceThreshold\nimport itertools\nfrom sklearn import datasets\nimport matplotlib.pyplot as plt\n\n\n\nresults = pd.read_csv('Data/cleanedResults.csv')\nresults\n\n\n\n\n\n\n\n\nresultId\nraceId\ndriverId\nconstructorId\nnumber\ngrid\nposition\npositionText\npositionOrder\npoints\nlaps\ntime\nfastestLap\nrank\nfastestLapTime\nfastestLapSpeed\nstatusId\nfastestLapTime_seconds\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10.0\n58\n1:34:50.616\n39\n2\n1:27.452\n218.300\n1\n87.452\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8.0\n58\n+5.478\n41\n3\n1:27.739\n217.586\n1\n87.739\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6.0\n58\n+8.163\n41\n5\n1:28.090\n216.719\n1\n88.090\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5.0\n58\n+17.181\n58\n7\n1:28.603\n215.464\n1\n88.603\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4.0\n58\n+18.014\n43\n1\n1:27.418\n218.385\n1\n87.418\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6433\n26079\n1110\n848\n3\n23\n15\n14\n14\n14\n0.0\n44\n+1:36.184\n35\n3\n1:49.841\n229.553\n1\n109.841\n\n\n6434\n26080\n1110\n825\n210\n20\n16\n15\n15\n15\n0.0\n44\n+1:41.754\n27\n14\n1:50.993\n227.171\n1\n110.993\n\n\n6435\n26081\n1110\n817\n213\n3\n19\n16\n16\n16\n0.0\n44\n+1:43.071\n25\n15\n1:50.994\n227.169\n1\n110.994\n\n\n6436\n26082\n1110\n858\n3\n2\n18\n17\n17\n17\n0.0\n44\n+1:44.476\n37\n9\n1:50.486\n228.213\n1\n110.486\n\n\n6437\n26083\n1110\n807\n210\n27\n0\n18\n18\n18\n0.0\n44\n+1:50.450\n26\n4\n1:49.907\n229.415\n1\n109.907\n\n\n\n\n6438 rows × 18 columns\n\n\n\n\ndef train_GNB_model(x_train, y_train, x_test, y_test, i_print = False):\n    \n    gnb = GaussianNB()\n    gnb.fit(x_train, y_train)\n    \n    y_pred = gnb.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_train = accuracy_score(y_train, gnb.predict(x_train))\n\n    if i_print:\n        print(accuracy * 100, accuracy_train * 100)\n    return accuracy_train, accuracy\n\n\nfeatures = ['driverId', 'constructorId', 'grid', 'fastestLapTime_seconds']\nX = results[features]\ny = results['position']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 82)\n\n\ntrain_GNB_model(X_train, y_train, X_test, y_test, i_print = True)\n\n12.18944099378882 13.902912621359222\n\n\n(0.13902912621359223, 0.12189440993788819)\n\n\n\nN = X.shape[0]\nl = [*range(N)]       # indices\ncut = int(0.7 * N)    # 80% of the list\nrandom.shuffle(l)     # randomize\ntrain_index = l[:cut] # first 80% of shuffled list\ntest_index = l[cut:] \n\n\n# VARIANCE THRESHOLD SEARCH\n\nx_var = np.var(X, axis = 0)\nnum_thresholds = 30\nthresholds = np.linspace(np.min(x_var), np.max(x_var), num_thresholds)\nthresholds = thresholds[1:-2]\n\nnum_features = []\ntrain_accuracies = []\ntest_accuracies = []\n\n(acc_train, acc_test) = train_GNB_model(X_train, y_train, X_test, y_test, i_print = True)\nnum_features.append(X.shape[1])\ntrain_accuracies.append(acc_train)\ntest_accuracies.append(acc_test)\n\nfor THRESHOLD in thresholds:\n    feature_selector = VarianceThreshold(threshold = THRESHOLD)\n    xtmp = feature_selector.fit_transform(X)\n    print(THRESHOLD, xtmp.shape[1])\n    \n    # Use the indices to split the reduced feature set\n    x_train_tmp = xtmp[train_index]\n    y_train_tmp = y.iloc[train_index]\n    x_test_tmp = xtmp[test_index]\n    y_test_tmp = y.iloc[test_index]\n    \n    (acc_train, acc_test) = train_GNB_model(x_train_tmp, y_train_tmp, x_test_tmp, y_test_tmp, i_print = False)\n             \n    # RECORD \n    num_features.append(xtmp.shape[1])\n    train_accuracies.append(acc_train)\n    test_accuracies.append(acc_test)\n\n12.18944099378882 13.902912621359222\n5593.803083955906 2\n11148.941345273512 1\n16704.079606591116 1\n22259.21786790872 1\n27814.356129226322 1\n33369.494390543936 1\n38924.63265186154 1\n44479.77091317914 1\n50034.909174496745 1\n55590.04743581435 1\n61145.18569713196 1\n66700.32395844956 1\n72255.46221976716 1\n77810.60048108477 1\n83365.73874240236 1\n88920.87700371997 1\n94476.01526503758 1\n100031.15352635518 1\n105586.29178767279 1\n111141.43004899038 1\n116696.568310308 1\n122251.7065716256 1\n127806.8448329432 1\n133361.98309426082 1\n138917.12135557842 1\n144472.25961689602 1\n150027.3978782136 1\n\n\n\nplt.plot(num_features, train_accuracies,'-or')\nplt.plot(num_features, test_accuracies,'-ob')\nplt.xlabel('Number of features')\nplt.ylabel('ACCURACY: Training (blue) and Test (red)')\nplt.show()\n\n\n\n\n\n(x,y) = datasets.load_digits(n_class = 4, return_X_y = True, as_frame = False)\nprint(\"LABEL=\",y[4])\nplt.gray()\nplt.matshow(x[4].reshape(8,8))\nplt.show()\n\nLABEL= 0\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\n\n\n\ndef maximize_CFS(x, y):\n    df_x = x\n    column_names = df_x.columns\n    \n    N = x.shape[0]\n    l = [*range(N)]       # indices\n    cut = int(0.7 * N)    # 80% of the list\n    random.shuffle(l)     # randomize\n    train_index = l[:cut] # first 80% of shuffled list\n    test_index = l[cut:]  # last 20%\n\n    max_accuracy = 0\n    y_train = y[train_index]\n    y_test = y[test_index]\n\n    for L in range(1, len(column_names) + 1):\n          for subset in itertools.combinations(column_names, L):\n               temp = df_x[list(subset)]\n               x_train = temp.iloc[train_index]\n               x_test = temp.iloc[test_index]\n               accuracy_train, accuracy = train_GNB_model(x_train, y_train, x_test, y_test)\n               if accuracy &gt; max_accuracy:\n                     max_accuracy = accuracy\n                     max_subset = list(subset)\n                     print(f'found new max: {max_accuracy}  optimal features = {max_subset} \\niteration= {L}, accuracy = {accuracy}')\n    return max_accuracy, max_subset\n\n\nx_opt = maximize_CFS(X, y)\n\nfound new max: 0.07349896480331262  optimal features = ['driverId'] \niteration= 1, accuracy = 0.07349896480331262\nfound new max: 0.14078674948240166  optimal features = ['grid'] \niteration= 1, accuracy = 0.14078674948240166\nfound new max: 0.14130434782608695  optimal features = ['driverId', 'grid', 'fastestLapTime_seconds'] \niteration= 3, accuracy = 0.14130434782608695\n\n\n\nFinal results for Naïve Bayes (NB) with Labeled Record Data\nReport and comment on the findings. It is required that you create code, appropriate visualizations, result summaries, confusion matrices, etc * I used three variables which is driver, the start grid position they are in the race, and the fastest lap time they did in the race to predict the final position they are at the end of the race. The result shows that there is no significant relationship between these three variables and the final position in a race which seems weird since the lap time and start grid position should have significant relationship with the final position by common sense.\nDescribe how the trained model is tested on the testing dataset. * Utilizing the optimal feature set identified in the previous section, we trained our Naive Bayes model on the record data. The model was then tested using the held-out test dataset to evaluate its predictive performance.\nDiscuss the evaluation metrics used to assess the performance of the Naive Bayes classifier (e.g., accuracy, precision, recall, F1-score). * For classification problems, several metrics are commonly employed to evaluate the performance: Accuracy: This is the most straightforward metric. It is the ratio of the number of correct predictions to the total predictions. Precision: Measures the number of correct positive predictions divided by the number of positive predictions made.\nDiscuss the concepts of overfitting and under-fitting and whether your model is doing it. * Overfitting occurs when a model learns the training data too well, capturing noise and outliers, thus performing poorly on new, unseen data. * Under-fitting happens when the model fails to capture the underlying trend of the data, leading to poor performance on both the training and test datasets. * The accuracy of training and testing does not have a significant difference. However, the accuracy of both training and test seems have a poor performance which could suggest a under-fitting.\nDiscuss the model’s performance in terms of accuracy and other relevant metrics. * The Naive Bayes classifier achieved an accuracy of 13% on the test dataset.\nDescribe how the project findings will be documented and reported, including the format of reports or presentations. * The findings of this project will be documented in a detailed report that includes: * Descriptive statistics of the dataset. * Visualizations that show the distribution of the data, feature importance, and the performance of our model. * A confusion matrix to provide insights into the types of errors our model is making.\ne.g. what is the output that you generate. What does the output mean? What does it tell you about your data? Does your model do a good job of predicting your test data? Include and discuss relevant visualizations, results, the confusion matrices, etc。 * Overall, I believe the model I used did not done a good job of predicting my test data since the accuracy of both training and testing is quite low. Plotted visualization seems well based on given data, however, there is nothing valid can be proved or illustrate by the visualization since the calculated accuracy is not right.\nWrite a conclusion paragraph interpreting the results. Note, this is not the same as a write-up of technical methodological details. * The reason for the low accuracy is probabily beacuse I only used the cleaned result dataset instead of the final cleaned and joined dataset which contains more variables that could affect the final position in a race. Reason for choosing only cleaned results datasete is that I think it contains all necessary needed variables to predict the final position in a race which is a wrong assumption by now. The right step should be use the final cleaned and joined dataset on this model."
  },
  {
    "objectID": "Pages/Introduction.html",
    "href": "Pages/Introduction.html",
    "title": "Introduction of F1",
    "section": "",
    "text": "Winning a race is the result of a combination of multiple factors, such as the driver’s skill, the car and engine performance, the pit stop strategy, the tire compounds, the weather, the competitors, and several random events that may occur during the race (Heine, 2021). We will look into the only calculatable variable that could affects a race: pit stop strategy. Pit stop strategy include the tire compounds strategy, which decided which laps the car should change its tires and which tires should be selected in order to obtain or maintain a better position in the race. Tire compounds decide how fast the lap time is, however, faster tire compound have shorter life of grip which means the car needs to back to the pit and change another set of tires. Teams often use different pit stop strategies that using different tire compound to achieve their own goal. Therefore adds an element of uncertainty which needs to be optimazed to help teams find the best timing and laps to pit stop.\n Here is Max Verstappen The three times World Dirver Champion by now, kicking his bursted tire in the Azerbaijan Grand Prix in year 2021. Max was kicking the bursted tire to raged on his tire, showing the importance of tire endurance in a race.\nThis analysis will look into F1 pit stop data and gain a better understanding of what is a better pit stop strategy.\nQuestions planed to answer:\n\nHow did pit stop duration change over time?\n\nThe overall pit stop duration would be approximately the same over time for one team in a race. Actions would cause increasing pit stop duration would be human error made by the driver or the team engineerings.\n\nIs there a relationship between pit stop durations and constructor/team?\n\nYes, observation in the EDA shows that there is a relationship between pit stop durations and constructors. Although it remains a weak relationship, still prove that there is a slight relation.\n\nIs there a relationship between pit stop durations and race circuit?\n\nNo, there is no obvious relationship between pit stop durations and race circuit since they pit stop durations are mostly depend on the driver and engineerings which would be perform consistantly in all race except some occasionally mistakes. Therefore, pit stop durations is not related to race circuit.\n\nWhat is the time spent in the pit lane as a percentage of the race for a driver?\n\nAverage pit stop duration in the pit lane for all race circuits is about 26 seconds and each driver do a 1.5 times pit stops in a race, and the mean race time for all race circuits is approaximately 6000 seconds. Therefore, time spent in the pit lance as a percentage of the race for a driver would be 0.65%.\n\nWho is the best constructor on pit stop performance?\n\nThe overall best constructor on pit stop performance in term of pit stop durations would be the Red Bull Racing.\n\nDoes the pit stop time affect the race?\n\nDefinitely yes, the pit stop durations would directly affects the race strategies for the team and usually a shorter pit stop duration would give more flexible time window for the next pit stop or sometimes undercut the rival.\n\nWhat is the lap number that most car choose to pit stop?\n\nThe lap number that most car choose to pit stop is actually dynamic. Pit stop timing need to be carefully designed before the race since each circuit is unique and have different time window for pit stop, however, there will always have troubles like accidents, safety cars, or even red flags that recalls all the cars back. Therefore, there is no obvious lap number that most car choose to pit stop, but the lap number to pit stop is a normal distribution that usually centered on the half of the overall lap numbers for a circuits.\n\nIs car doing more pit stops have advantages on those who do less pit stops?\n\nTechnically yes, but different car have different performance on the same formula or tire. Softer tire have more friction but also easier to be wore out. Alfa Romeo team this season had awful performance using soft and medium tire compare to other teams, but their performance on hard tire would out-perform others a lot which is quite strange to see. Back to the question, pit stop is dependent on the team performance on tire, which is unimagable difficult for me to do a thorough analysis on it.\n\nWho have the fastest pit stop and did he get championship that year?\n\nCurrent fastest pit stop was made during lap 27 of Qatar Grand Prix by Lando Norris from McLaren in the 2023 season. However, he did not get the World Driver Champion this year.\n\nIs the pit stop time consistent with driver’s lap time?\n\nThere is clear relationship between pit stop time and driver’s lap time.\n\n\nHere are some references:\n[Heine, 2021] - Oscar F. Carrasco Heine. (2021). On the Optimization of Pit-Stop Strategies via Dynamic Programming.\n[Martinetti, 2021] - Alberto Martinetti. (2021). Gone in 2s: a deep dive into perfection analysing the collaborative maintenance pitstop of Formula 1. Journal of Quality in Maintenance Engineering."
  },
  {
    "objectID": "Pages/Feature selection for text data.html",
    "href": "Pages/Feature selection for text data.html",
    "title": "Feature Selection for Text Data",
    "section": "",
    "text": "## import libraries\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nimport random\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nimport time\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_selection import VarianceThreshold\n\n\n\ndf = pd.read_csv(\"Data/comments.csv\")\nprint(df.shape)\nprint(df.columns)\n\n(1344, 2)\nIndex(['level', 'comments'], dtype='object')\n\n\n\nreviews=[]\ny=[]\n#ITERATE OVER ROWS\n# for i in range(0,10):  \nfor i in range(0,df.shape[0]):\n    # QUICKLY CLEAN TEXT\n    keep=\"abcdefghijklmnopqrstuvwxyz \"\n    replace=\".,!;\"\n    tmp=\"\"\n    for char in df[\"comments\"][i].replace(\"&lt;br /&gt;\",\"\").lower():\n        if char in replace:\n            tmp+=\" \"\n        if char in keep:\n            tmp+=char\n    tmp=\" \".join(tmp.split())\n    reviews.append(tmp)\n    # CONVERT STRINGS TO INT TAGS\n    if(df[\"level\"][i]==\"positive\"):\n        y.append(1)\n    if(df[\"level\"][i]==\"negative\"):\n        y.append(0)\n\n    #PRINT FIRST COUPLE REVIEWS\n    if(i&lt;3):\n        print(i)\n        print(df[\"comments\"][i].replace(\"&lt;br /&gt;\",\"\"),'\\n')\n        print(tmp)\n        print(df[\"level\"][i],y[i])\n\n0\nHow does a bastard, orphan, son of a whore and a \n\nhow does a bastard orphan son of a whore and a\nnegative 0\n1\nScotsman, dropped in the middle of a forgotten \n\nscotsman dropped in the middle of a forgotten\nnegative 0\n2\nSpot in the Caribbean by providence, impoverished, in squalor \n\nspot in the caribbean by providence impoverished in squalor\nnegative 0\n\n\n\ny=np.array(y)\n\n\ndef vectorize(corpus,MAX_FEATURES):\n    vectorizer=CountVectorizer(max_features=MAX_FEATURES,stop_words=\"english\")   \n    # RUN COUNT VECTORIZER ON OUR COURPUS \n    Xs  =  vectorizer.fit_transform(corpus)   \n    X=np.array(Xs.todense())\n    #CONVERT TO ONE-HOT VECTORS (can also be done with binary=true in CountVectorizer)\n    maxs=np.max(X,axis=0)\n    return (np.ceil(X/maxs),vectorizer.vocabulary_)\n\n(x,vocab0)=vectorize(reviews,MAX_FEATURES=10000)\n\n\ndf2=pd.DataFrame(x)\ns = df2.sum(axis=0)\ndf2=df2[s.sort_values(ascending=False).index[:]]\nprint(df2.head())\n\n   723   1315  795   405   1674  1205  167   836   639   1230  ...  652   \\\n0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n\n   633   651   650   646   645   643   642   636   1676  \n0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[5 rows x 1677 columns]\n\n\n\nN = x.shape[0]\nl = [*range(N)]     # indices\ncut = int(0.8 * N) #80% of the list\nrandom.shuffle(l)   # randomize\ntrain_index = l[:cut] # first 80% of shuffled list\ntest_index = l[cut:] # last 20% of shuffled list\n\nprint(train_index[0:10])\nprint(test_index[0:10])\n\n[351, 1271, 1027, 1115, 920, 301, 260, 572, 1078, 779]\n[1274, 86, 931, 1125, 1334, 471, 370, 1338, 915, 741]\n\n\n\ndef train_MNB_model(X,Y,i_print=False):\n\n    if(i_print):\n        print(X.shape,Y.shape)\n\n    #SPLIT\n    x_train=X[train_index]\n    y_train=Y[train_index].flatten()\n\n    x_test=X[test_index]\n    y_test=Y[test_index].flatten()\n\n    # INITIALIZE MODEL \n    model = MultinomialNB()\n\n    # TRAIN MODEL \n    start = time.process_time()\n    model.fit(x_train,y_train)\n    time_train=time.process_time() - start\n\n    # LABEL PREDICTIONS FOR TRAINING AND TEST SET \n    start = time.process_time()\n    yp_train = model.predict(x_train)\n    yp_test = model.predict(x_test)\n    time_eval=time.process_time() - start\n\n    acc_train= accuracy_score(y_train, yp_train)*100\n    acc_test= accuracy_score(y_test, yp_test)*100\n\n    if(i_print):\n        print(acc_train,acc_test,time_train,time_eval)\n\n    return (acc_train,acc_test,time_train,time_eval)\n\n\n#TEST\nprint(type(x),type(y))\nprint(x.shape,y.shape)\n(acc_train,acc_test,time_train,time_eval)=train_MNB_model(x,y,i_print=True)\n\n&lt;class 'numpy.ndarray'&gt; &lt;class 'numpy.ndarray'&gt;\n(1344, 1677) (1344,)\n(1344, 1677) (1344,)\n88.27906976744187 61.71003717472119 0.016790999999999556 0.00834899999999994\n\n\n\n##UTILITY FUNCTION TO INITIALIZE RELEVANT ARRAYS\ndef initialize_arrays():\n    global num_features,train_accuracies\n    global test_accuracies,train_time,eval_time\n    num_features=[]\n    train_accuracies=[]\n    test_accuracies=[]\n    train_time=[]\n    eval_time=[]\n\n\n# INITIALIZE ARRAYS\ninitialize_arrays()\n\n# DEFINE SEARCH FUNCTION\ndef partial_grid_search(num_runs, min_index, max_index):\n    for i in range(1, num_runs+1):\n        # SUBSET FEATURES \n        upper_index=min_index+i*int((max_index-min_index)/num_runs)\n        xtmp=x[:,0:upper_index]\n\n        #TRAIN \n        (acc_train,acc_test,time_train,time_eval)=train_MNB_model(xtmp,y,i_print=False)\n\n        if(i%5==0):\n            print(i,upper_index,xtmp.shape[1],acc_train,acc_test)\n            \n        #RECORD \n        num_features.append(xtmp.shape[1])\n        train_accuracies.append(acc_train)\n        test_accuracies.append(acc_test)\n        train_time.append(time_train)\n        eval_time.append(time_eval)\n\n# DENSE SEARCH (SMALL NUMBER OF FEATURES (FAST))\npartial_grid_search(num_runs=100, min_index=0, max_index=1000)\n\n# SPARSE SEARCH (LARGE NUMBER OF FEATURES (SLOWER))\npartial_grid_search(num_runs=20, min_index=1000, max_index=10000)\n\n5 50 50 63.53488372093024 56.877323420074354\n10 100 100 65.67441860465117 57.249070631970255\n15 150 150 66.23255813953489 56.877323420074354\n20 200 200 67.72093023255815 57.249070631970255\n25 250 250 69.48837209302326 57.99256505576208\n30 300 300 70.41860465116278 57.62081784386617\n35 350 350 71.25581395348837 57.99256505576208\n40 400 400 72.74418604651163 59.479553903345725\n45 450 450 73.76744186046513 60.223048327137555\n50 500 500 74.4186046511628 59.85130111524164\n55 550 550 75.25581395348837 59.479553903345725\n60 600 600 76.65116279069767 58.36431226765799\n65 650 650 78.6046511627907 64.31226765799256\n70 700 700 79.16279069767442 63.19702602230484\n75 750 750 80.0 63.94052044609665\n80 800 800 80.74418604651163 61.71003717472119\n85 850 850 80.55813953488372 61.33828996282528\n90 900 900 81.3953488372093 61.71003717472119\n95 950 950 81.95348837209302 63.94052044609665\n100 1000 1000 82.6046511627907 63.56877323420075\n5 3250 1677 88.27906976744187 61.71003717472119\n10 5500 1677 88.27906976744187 61.71003717472119\n15 7750 1677 88.27906976744187 61.71003717472119\n20 10000 1677 88.27906976744187 61.71003717472119\n\n\n\n#UTILITY FUNCTION TO PLOT RESULTS\ndef plot_results(path_root):\n\n    #PLOT-1\n    plt.plot(num_features,train_accuracies,'-or')\n    plt.plot(num_features,test_accuracies,'-ob')\n    plt.xlabel('Number of features')\n    plt.ylabel('ACCURACY: Training (red) and Test (blue)')\n    plt.savefig(path_root+'-1.png')\n    plt.show()\n\n    # #PLOT-2\n    plt.plot(num_features,train_time,'-or')\n    plt.plot(num_features,eval_time,'-ob')\n    plt.xlabel('Number of features')\n    plt.ylabel('Runtime: training time (red) and evaluation time(blue)')\n    plt.savefig(path_root+'-2.png')\n    plt.show()\n\n    # #PLOT-3\n    plt.plot(np.array(test_accuracies),train_time,'-or')\n    plt.plot(np.array(test_accuracies),eval_time,'-ob')\n    plt.xlabel('test_accuracies')\n    plt.ylabel('Runtime: training time (red) and evaluation time (blue)')\n    plt.savefig(path_root+'-3.png')\n    plt.show()\n\n    # #PLOT-3\n    plt.plot(num_features,np.array(train_accuracies)-np.array(test_accuracies),'-or')\n    plt.xlabel('Number of features')\n    plt.ylabel('train_accuracies-test_accuracies')\n    plt.savefig(path_root+'-4.png')\n    plt.show()\n\n\nplot_results('results')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_var=np.var(x,axis=0)\nprint(np.min(x_var))\nprint(np.max(x_var))\n\n0.0007434940121882086\n0.04197170404620044\n\n\n\nfrom sklearn.feature_selection import VarianceThreshold\n\n# DEFINE GRID OF THRESHOLDS \nnum_thresholds=30\nthresholds=np.linspace(np.min(x_var),np.max(x_var),num_thresholds)\n\n#DOESN\"T WORK WELL WITH EDGE VALUES \nthresholds=thresholds[1:-2]; #print(thresholds)\n\n# INITIALIZE ARRAYS\ninitialize_arrays()\n\n# SEARCH FOR OPTIMAL THRESHOLD\nfor THRESHOLD in thresholds:\n    feature_selector = VarianceThreshold(threshold=THRESHOLD)\n    xtmp=feature_selector.fit_transform(x)\n    print(\"THRESHOLD =\",THRESHOLD, xtmp.shape[1])\n\n    (acc_train,acc_test,time_train,time_eval)=train_MNB_model(xtmp,y,i_print=False)\n             \n    #RECORD \n    num_features.append(xtmp.shape[1])\n    train_accuracies.append(acc_train)\n    test_accuracies.append(acc_test)\n    train_time.append(time_train)\n    eval_time.append(time_eval)\n\nTHRESHOLD = 0.0021651564271541477 337\nTHRESHOLD = 0.0035868188421200866 143\nTHRESHOLD = 0.005008481257086026 86\nTHRESHOLD = 0.006430143672051965 61\nTHRESHOLD = 0.007851806087017903 45\nTHRESHOLD = 0.009273468501983842 36\nTHRESHOLD = 0.01069513091694978 27\nTHRESHOLD = 0.01211679333191572 21\nTHRESHOLD = 0.013538455746881659 18\nTHRESHOLD = 0.014960118161847598 17\nTHRESHOLD = 0.016381780576813536 12\nTHRESHOLD = 0.017803442991779477 11\nTHRESHOLD = 0.019225105406745418 8\nTHRESHOLD = 0.020646767821711355 6\nTHRESHOLD = 0.022068430236677292 5\nTHRESHOLD = 0.023490092651643233 5\nTHRESHOLD = 0.024911755066609174 4\nTHRESHOLD = 0.02633341748157511 4\nTHRESHOLD = 0.027755079896541048 4\nTHRESHOLD = 0.02917674231150699 2\nTHRESHOLD = 0.03059840472647293 2\nTHRESHOLD = 0.03202006714143886 1\nTHRESHOLD = 0.0334417295564048 1\nTHRESHOLD = 0.03486339197137074 1\nTHRESHOLD = 0.03628505438633668 1\nTHRESHOLD = 0.03770671680130262 1\nTHRESHOLD = 0.039128379216268556 1\n\n\n\nplot_results('results')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinal results for Naïve Bayes (NB) with Labeled Record Data\nReport and comment on the findings. It is required that you create code, appropriate visualizations, result summaries, confusion matrices, etc * The accuracy we get from the model is not greater than 90%, however, the balanced precision and recall shows that the model is still doing a good job\nDescribe how the trained model is tested on the testing dataset. * Utilizing the optimal feature set identified in the previous section, we trained our Naive Bayes model on the record data. The model was then tested using the held-out test dataset to evaluate its predictive performance.\nDiscuss the evaluation metrics used to assess the performance of the Naive Bayes classifier (e.g., accuracy, precision, recall, F1-score). * For classification problems, several metrics are commonly employed to evaluate the performance: Accuracy: This is the most straightforward metric. It is the ratio of the number of correct predictions to the total predictions. Precision: Measures the number of correct positive predictions divided by the number of positive predictions made.\nDiscuss the concepts of overfitting and under-fitting and whether your model is doing it. * Overfitting occurs when a model learns the training data too well, capturing noise and outliers, thus performing poorly on new, unseen data. * Under-fitting happens when the model fails to capture the underlying trend of the data, leading to poor performance on both the training and test datasets. * The accuracy of training and testing does not have a significant difference. However, the accuracy of both training and test seems have a poor performance which could suggest a under-fitting.\nDiscuss the model’s performance in terms of accuracy and other relevant metrics. * The Naive Bayes classifier achieved an accuracy of 88% which could be count as good performance\nDescribe how the project findings will be documented and reported, including the format of reports or presentations. * The findings of this project will be documented in a detailed report that includes: * Descriptive statistics of the dataset. * Visualizations that show the distribution of the data, feature importance, and the performance of our model. * A confusion matrix to provide insights into the types of errors our model is making.\ne.g. what is the output that you generate. What does the output mean? What does it tell you about your data? Does your model do a good job of predicting your test data? Include and discuss relevant visualizations, results, the confusion matrices, etc。 * For the 88% of accuracy of the model, I can predict that when a comment is been identified as a status of level, there is a strong likelihood that prediction is accurate.\nWrite a conclusion paragraph interpreting the results. Note, this is not the same as a write-up of technical methodological details. * It’s evident that our model demonstrates a commendable ability to discern between the positive and negative classes in the provided dataset. While the overall accuracy is robust, signaling a general correctness in predictions. This high precision suggests that when our model identifies an instance as positive, there’s a strong likelihood of that prediction being accurate, minimizing the risk of false alarms."
  },
  {
    "objectID": "Pages/Data Gathering.html",
    "href": "Pages/Data Gathering.html",
    "title": "Data Gathering",
    "section": "",
    "text": "The raw data collected use Python: The process of collecting data using Python API was not easy, the website I requested data from has the data in the XML format which caused trouble converting the data into a data frame in Python. I realized it later while trying to read that data and unavoidably wasted a huge amount of time trying to figure out how to convert an XML format into CSV. \nThe raw data collected use R The process of using R API to request data from a shared google speadsheet does not require a credential from google drive since my google account have permission on the public speadsheet. I used R package googlesheet4 which have the function of getting a google sheets directly and then convert it into a CSV file."
  },
  {
    "objectID": "Pages/Code.html",
    "href": "Pages/Code.html",
    "title": "Code for cleaning data",
    "section": "",
    "text": "Data collected using Python API and cleaning process https://github.com/anly501/dsan-5000-project-VaBrox/blob/main/codes/01-data-gathering/pythonClean.py\nData collected using R API and cleaning process https://github.com/anly501/dsan-5000-project-VaBrox/blob/main/codes/01-data-gathering/rClean.R\nEDA process https://github.com/anly501/dsan-5000-project-VaBrox/blob/main/codes/EDA%20process.ipynb\nFeature selection and NB for record data https://github.com/anly501/dsan-5000-project-VaBrox/blob/main/codes/Feature%20selection%20for%20record%20data.ipynb\nFeature selection and NB for text data https://github.com/anly501/dsan-5000-project-VaBrox/blob/main/codes/Feature%20selection%20for%20text%20data.ipynb"
  },
  {
    "objectID": "Pages/Decision Tree.html",
    "href": "Pages/Decision Tree.html",
    "title": "Decison Tree",
    "section": "",
    "text": "A Decision Tree is a model that resembles a tree structure. It begins with one question node as the tip of a tree then splits into different branches that lead to lower nodes questions until it reaches the lowest branches known as a leaf. This whole process is similar to the logical process of deciding yes or no, therefore, this method can help in making decisions and that is where its name came from.\nHowever, the defect of Decision Tree can not be easily ignored. They can oversimplify complex problems and are prone to overfitting a model.\nDecision Tree is still a powerful and rather simplified tool to provide an insights of the data therefore help in decision making process.\n\nTools and Libraries:\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn import tree\nfrom sklearn.datasets import make_classification\nfrom sklearn.svm import SVC\n\n\n\n\nEDA Process\n\nresults = pd.read_csv('Data/results.csv')\nmergedPitStops = pd.read_csv('Data/mergedPitStops.csv')\n\n\ndata = pd.merge(mergedPitStops,results[['driverId', 'position']], left_on = 'driverId', right_index = True, how = 'left')\n\n/var/folders/j9/cbm31jzn08z95c3hz67rzjyc0000gn/T/ipykernel_60702/367688774.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'driverId_x'} in the result is deprecated and will raise a MergeError in a future version.\n  data = pd.merge(mergedPitStops,results[['driverId', 'position']], left_on = 'driverId', right_index = True, how = 'left')\n\n\n\ncolumn_to_move = data.pop('position')\ndata.insert(2, 'position', column_to_move)\ndata = data.replace('\\\\N', pd.NA)\ndata = data.dropna()\n\n\nselected_columns = ['driverId_x', 'stop', 'position', 'seconds', 'circuitId_x', 'constructorId_x']\nselected_df = data[selected_columns]\nselected_df['circuitId_x'] = pd.to_numeric(selected_df['circuitId_x'], errors='coerce')\nselected_df.head()\n\n/var/folders/j9/cbm31jzn08z95c3hz67rzjyc0000gn/T/ipykernel_60702/2425359013.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  selected_df['circuitId_x'] = pd.to_numeric(selected_df['circuitId_x'], errors='coerce')\n\n\n\n\n\n\n\n\n\ndriverId_x\ndriverId_x\nstop\nposition\nseconds\ncircuitId_x\nconstructorId_x\n\n\n\n\n0\n153\n153\n1\n6\n26.898\n17.0\n5\n\n\n1\n153\n153\n2\n6\n24.463\n17.0\n5\n\n\n2\n153\n153\n3\n6\n26.348\n17.0\n5\n\n\n6\n4\n4\n1\n5\n23.251\n17.0\n6\n\n\n7\n4\n4\n2\n5\n24.733\n17.0\n6\n\n\n\n\n\n\n\n\n\nMethods\n\nX = selected_df.drop('position', axis = 1)  # features\ny = selected_df['position'] \nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 82)\n\nprint(\"TRAINING SHAPES:\",x_train.shape, y_train.shape)\nprint(\"TEST SHAPES:\",x_test.shape, y_test.shape)\n\nTRAINING SHAPES: (3784, 6) (3784,)\nTEST SHAPES: (947, 6) (947,)\n\n\n\nTraining the model\nTrain a sklearn decision tree model on x_train, y_train\n\nmodel = tree.DecisionTreeClassifier()\nmodel = model.fit(x_train, y_train)\n\nUse the model to make predictions for the training and test set\n\nyp_train = model.predict(x_train)\nyp_test = model.predict(x_test)\n\n\ndef confusion_plot(y_true, y_pred, class_labels):\n    # Calculate the confusion matrix\n    cm = confusion_matrix(y_true, y_pred, labels=class_labels)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n    \n    # Print the confusion matrix plot\n    disp.plot()\n    plt.show()\n\n\n# Generate predictions using the decision tree model with a depth of 4 for both train and test sets\ndt_classifier_depth_4 = DecisionTreeClassifier(max_depth = 4, random_state = 82)\ndt_classifier_depth_4.fit(x_train, y_train)\nyp_train = dt_classifier_depth_4.predict(x_train)\nyp_test = dt_classifier_depth_4.predict(x_test)\n\n# Get the unique class labels\nclass_labels = dt_classifier_depth_4.classes_\n\n# Plot the confusion matrix for the training set\nprint(\"------TRAINING------\")\nconfusion_plot(y_train, yp_train, class_labels)\n\n# Plot the confusion matrix for the test set\nprint(\"------TEST------\")\nconfusion_plot(y_test, yp_test, class_labels)\n\n------TRAINING------\n------TEST------\n\n\n\n\n\n\n\n\n\n\nVisualize the tree\n\n# INSERT CODE TO WRITE A FUNCTION \"def plot_tree(model,X,Y)\" VISUALIZE THE DECISION TREE (see https://mljar.com/blog/visualize-decision-tree/ for an example)\ndef plot_tree(model, x, y):\n    fig = plt.figure(figsize = (25, 20))\n    _ =tree.plot_tree(model, filled = True)\n    plt.show()\n\nplot_tree(model, X, y)\n\n\n\n\n\n\nHyper-parameter Tuning\nThen use the following code to loop over possible hyper-parameters values\n\ntest_results = []\ntrain_results = []\n\nfor num_layer in range(1,20):\n    model = tree.DecisionTreeClassifier(max_depth = num_layer)\n    model = model.fit(x_train, y_train)\n\n    yp_train = model.predict(x_train)\n    yp_test = model.predict(x_test)\n\n    # print(y_pred.shape)\n    test_results.append([num_layer ,accuracy_score(y_test, yp_test), recall_score(y_test, yp_test, average='macro'), recall_score(y_test, yp_test, average='weighted')])\n    train_results.append([num_layer, accuracy_score(y_train, yp_train), recall_score(y_train, yp_train, average='macro'), recall_score(y_train, yp_train, average='weighted')])\n\nThen generate the three plots below\n\ntrain_df = pd.DataFrame(train_results, columns = ['max_depth', 'accuracy', 'recall_negative', 'recall_positive'])\ntest_df = pd.DataFrame(test_results, columns = ['max_depth', 'accuracy', 'recall_negative', 'recall_positive'])\n\nplt.plot(train_df['max_depth'], train_df['accuracy'], 'o-', color = 'blue', label = 'Train Accuracy')\nplt.plot(test_df['max_depth'], test_df['accuracy'], 'o-', color = 'red', label = 'Test Accuracy')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Accuracy (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nplt.plot(train_df['max_depth'], train_df['recall_negative'], 'o-', color = 'blue', label = 'Train Negative Recall')\nplt.plot(test_df['max_depth'], test_df['recall_negative'], 'o-', color = 'red', label = 'Test Negative Recall')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Recall (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nplt.plot(train_df['max_depth'], train_df['recall_positive'], 'o-', color = 'blue', label = 'Train Positive Recall')\nplt.plot(test_df['max_depth'], test_df['recall_positive'], 'o-', color = 'red', label = 'Test Positive Recall')\nplt.xlabel('Number of layers in decision tree (max_depth)')\nplt.ylabel('Recall (Y = 0): Training (blue) and Test (red)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nTrain optimal model\nRe-train the decision tree using the optimal hyper-parameter obtained from the plot above\n\nmodel = tree.DecisionTreeClassifier(max_depth = 4)\nmodel = model.fit(x_train, y_train)\n\nyp_train = model.predict(x_train)\nyp_test = model.predict(x_test)\n\n\n# RUN THE FOLLOWING CODE TO EVALUATE YOUR MODEL\nclass_labels = model.classes_\n\nprint(\"------TRAINING------\")\nconfusion_plot(y_train, yp_train, class_labels)\nprint(\"------TEST------\")\nconfusion_plot(y_test, yp_test, class_labels)\n\nplot_tree(model, X, y)\n\n------TRAINING------\n------TEST------\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary\nBased on the training sets’ confusion matrixs and plots, there is a higher chance that this model is overfitting since the accuracy of the training is kind of higher than expected."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "5000 project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKaiyang Li kl1106\n\n\nI am Kaiyang Li from Zhengzhou City China. I did my undergraduate in Statistics at Rutgers New Jersey. I am into cars and love modifying them but unfortunately, I just sold my car since it is really inconvenient to own a car in DC. I sometimes work out and do some weight lifting still looking for a partner so just text me if you are also looking for a reliable spot partner.\n\n\n\n\n\n\n\n\nAcademic Interests\n\n\n\nAs for now, I am interested in the data analytics track since I want to work as a strategy engineer in a racing team, which helps the team on the part of making strategic pit stops in a race.\n\n\n2023-Current: Georgetown University\n\n\n2019-2022: Rutges, The State University of New Jersey\n\n\n2018-2019: Miami University"
  },
  {
    "objectID": "Pages/EDA process.html",
    "href": "Pages/EDA process.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "## import necessary libraries \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport numpy as np\n\n\n## read dataset needed for this project\n## reason the following datasets been choosen is that the main purpose of this project is to find the relationship between pit stop time and \n## drivers with constructors. Therefore, dataset like qualifying and sprint race are deserted since they have no obvious relation with the \n## purpose of this project.\ndrivers = pd.read_csv('Data/drivers.csv')\npitStops = pd.read_csv('Data/pit_stops.csv')\nconstructors = pd.read_csv('Data/constructors.csv')\nraces = pd.read_csv('Data/races.csv')\ncircuits = pd.read_csv('Data/circuits.csv')\nresults = pd.read_csv('Data/results.csv')\n\n\nCheck the drivers dataset:\n\ndrivers.head()\n\n\n\n\n\n\n\n\ndriverId\ndriverRef\nnumber\ncode\nforename\nsurname\ndob\nnationality\nurl\n\n\n\n\n0\n1\nhamilton\n44\nHAM\nLewis\nHamilton\n1985-01-07\nBritish\nhttp://en.wikipedia.org/wiki/Lewis_Hamilton\n\n\n1\n2\nheidfeld\n\\N\nHEI\nNick\nHeidfeld\n1977-05-10\nGerman\nhttp://en.wikipedia.org/wiki/Nick_Heidfeld\n\n\n2\n3\nrosberg\n6\nROS\nNico\nRosberg\n1985-06-27\nGerman\nhttp://en.wikipedia.org/wiki/Nico_Rosberg\n\n\n3\n4\nalonso\n14\nALO\nFernando\nAlonso\n1981-07-29\nSpanish\nhttp://en.wikipedia.org/wiki/Fernando_Alonso\n\n\n4\n5\nkovalainen\n\\N\nKOV\nHeikki\nKovalainen\n1981-10-19\nFinnish\nhttp://en.wikipedia.org/wiki/Heikki_Kovalainen\n\n\n\n\n\n\n\n\n## check how many \\N are there in the column number since not all drivers had a number in the race\nnum_null = (drivers['number'] == r'\\N').sum()\nnum_null\n\n803\n\n\n\ndrivers['driverName'] = drivers['forename'] + ' ' + drivers['surname']\ndrivers = drivers.rename(columns = {'nationality' : 'driverNationality'})\n\n\n## we can drop unrelated variables since they obviously will not influence the data analysis\ndrivers = drivers.drop(labels = ['driverRef', 'number', 'code','forename', 'surname', 'dob', 'url'], axis = 1)\n\n\n\nCheck the pitStops dataset:\n\npitStops.head()\n\n\n\n\n\n\n\n\nraceId\ndriverId\nstop\nlap\ntime\nduration\nmilliseconds\n\n\n\n\n0\n841\n153\n1\n1\n17:05:23\n26.898\n26898\n\n\n1\n841\n30\n1\n1\n17:05:52\n25.021\n25021\n\n\n2\n841\n17\n1\n11\n17:20:48\n23.426\n23426\n\n\n3\n841\n4\n1\n12\n17:22:34\n23.251\n23251\n\n\n4\n841\n13\n1\n13\n17:24:10\n23.842\n23842\n\n\n\n\n\n\n\n\n## here we can get the statistical information about the pitStops dataset\npitStops.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nraceId\n10089.0\n962.774011\n81.144375\n841.0\n888.0\n958.0\n1035.0\n1110.0\n\n\ndriverId\n10089.0\n523.998910\n389.698555\n1.0\n18.0\n815.0\n831.0\n858.0\n\n\nstop\n10089.0\n1.759738\n0.916282\n1.0\n1.0\n2.0\n2.0\n6.0\n\n\nlap\n10089.0\n25.312023\n14.729775\n1.0\n13.0\n25.0\n36.0\n78.0\n\n\nmilliseconds\n10089.0\n75348.633363\n278858.845817\n12897.0\n21914.0\n23570.0\n26202.0\n3069017.0\n\n\n\n\n\n\n\n\npitStops = pitStops.rename(columns = {'time' : 'pitTime'})\npitStops['seconds'] = pitStops['milliseconds'].apply(lambda x: x/1000)\n\n\npitStops = pitStops.drop(labels = ['milliseconds'], axis = 1)\n\n\n\nChecking the constructors dataset:\n\nconstructors.head()\n\n\n\n\n\n\n\n\nconstructorId\nconstructorRef\nname\nnationality\nurl\n\n\n\n\n0\n1\nmclaren\nMcLaren\nBritish\nhttp://en.wikipedia.org/wiki/McLaren\n\n\n1\n2\nbmw_sauber\nBMW Sauber\nGerman\nhttp://en.wikipedia.org/wiki/BMW_Sauber\n\n\n2\n3\nwilliams\nWilliams\nBritish\nhttp://en.wikipedia.org/wiki/Williams_Grand_Pr...\n\n\n3\n4\nrenault\nRenault\nFrench\nhttp://en.wikipedia.org/wiki/Renault_in_Formul...\n\n\n4\n5\ntoro_rosso\nToro Rosso\nItalian\nhttp://en.wikipedia.org/wiki/Scuderia_Toro_Rosso\n\n\n\n\n\n\n\n\n## we also need to drop an unnecessary column here which is the url column\nconstructors = constructors.drop(labels = ['url'], axis = 1)\n\n\nconstructors = constructors.rename(columns={'name' : 'constructorName', 'nationality' : 'constructorNationality'})\n\n\n\nChecking the races dataset:\n\nraces.head()\n\n\n\n\n\n\n\n\nraceId\nyear\nround\ncircuitId\nname\ndate\ntime\nurl\nfp1_date\nfp1_time\nfp2_date\nfp2_time\nfp3_date\nfp3_time\nquali_date\nquali_time\nsprint_date\nsprint_time\n\n\n\n\n0\n1\n2009\n1\n1\nAustralian Grand Prix\n2009-03-29\n06:00:00\nhttp://en.wikipedia.org/wiki/2009_Australian_G...\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\n\n1\n2\n2009\n2\n2\nMalaysian Grand Prix\n2009-04-05\n09:00:00\nhttp://en.wikipedia.org/wiki/2009_Malaysian_Gr...\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\n\n2\n3\n2009\n3\n17\nChinese Grand Prix\n2009-04-19\n07:00:00\nhttp://en.wikipedia.org/wiki/2009_Chinese_Gran...\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\n\n3\n4\n2009\n4\n3\nBahrain Grand Prix\n2009-04-26\n12:00:00\nhttp://en.wikipedia.org/wiki/2009_Bahrain_Gran...\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\n\n4\n5\n2009\n5\n4\nSpanish Grand Prix\n2009-05-10\n12:00:00\nhttp://en.wikipedia.org/wiki/2009_Spanish_Gran...\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\\N\n\n\n\n\n\n\n\n\n## check the ratio of \\N in the fp and quali columns since we can observe huge amount of \\N  \nvalueCheck = '\\\\N'\ntotal = len(races)\nvalue = races[races[['fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time']].isin([valueCheck]).any(axis=1)].shape[0]\nratio = value / total\nprint('Ratio is:', ratio)\n\nRatio is: 1.0\n\n\n\n# since the ratio of \\N in those columns is 1, therefore, we can drop those columns snice they will not affect the analysis\nraces = races.drop(labels = ['fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time', 'url'], axis = 1)\n\n\nraces = races.rename(columns = {'name' : 'raceName'})\n\n\n\nCheck the circuits dataset\n\ncircuits.head()\n\n\n\n\n\n\n\n\ncircuitId\ncircuitRef\nname\nlocation\ncountry\nlat\nlng\nalt\nurl\n\n\n\n\n0\n1\nalbert_park\nAlbert Park Grand Prix Circuit\nMelbourne\nAustralia\n-37.84970\n144.96800\n10\nhttp://en.wikipedia.org/wiki/Melbourne_Grand_P...\n\n\n1\n2\nsepang\nSepang International Circuit\nKuala Lumpur\nMalaysia\n2.76083\n101.73800\n18\nhttp://en.wikipedia.org/wiki/Sepang_Internatio...\n\n\n2\n3\nbahrain\nBahrain International Circuit\nSakhir\nBahrain\n26.03250\n50.51060\n7\nhttp://en.wikipedia.org/wiki/Bahrain_Internati...\n\n\n3\n4\ncatalunya\nCircuit de Barcelona-Catalunya\nMontmeló\nSpain\n41.57000\n2.26111\n109\nhttp://en.wikipedia.org/wiki/Circuit_de_Barcel...\n\n\n4\n5\nistanbul\nIstanbul Park\nIstanbul\nTurkey\n40.95170\n29.40500\n130\nhttp://en.wikipedia.org/wiki/Istanbul_Park\n\n\n\n\n\n\n\n\ncircuits.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 77 entries, 0 to 76\nData columns (total 9 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   circuitId   77 non-null     int64  \n 1   circuitRef  77 non-null     object \n 2   name        77 non-null     object \n 3   location    77 non-null     object \n 4   country     77 non-null     object \n 5   lat         77 non-null     float64\n 6   lng         77 non-null     float64\n 7   alt         77 non-null     object \n 8   url         77 non-null     object \ndtypes: float64(2), int64(1), object(6)\nmemory usage: 5.5+ KB\n\n\n\n## we still gonna drop the column url since it will not affect our analysis\ncircuits = circuits.drop(labels = ['url'], axis = 1)\n\n\ncircuits = circuits.rename(columns = {'name' : 'circuitName', 'location' : 'circuitLocation', 'country' : 'circuitCountry'})\n\n\n## infomation provided by the circuits dataset that can be used in the analysis is the circuitid and name which we will compare the relationship \n## between pit stop time and each circuit.\n## however, we can see that the dataset also provided us with the latitude, longtitude, and altitude of each circuits, we can plot the circuits map\n## to make people who does not familiar with F1 race have a better understanding of it.\nimport folium\ncoordinates = []\nfor lat, lng in zip(circuits['lat'], circuits['lng']):\n    coordinates.append([lat, lng])\nmaps = folium.Map(zoom_start = 2, title = 'Stamen Watercolor')\nfor i, j in zip(coordinates, circuits.circuitName):\n    marker = folium.Marker(\n        location = i,\n        icon = folium.Icon(icon = \"car\", color = 'green', prefix = 'fa'),\n        popup = \"&lt;strong&gt;{0}&lt;/strong&gt;\".format(j))\n    marker.add_to(maps)\nmaps\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCheck the results dataset\n\nresults.head()\n\n\n\n\n\n\n\n\nresultId\nraceId\ndriverId\nconstructorId\nnumber\ngrid\nposition\npositionText\npositionOrder\npoints\nlaps\ntime\nmilliseconds\nfastestLap\nrank\nfastestLapTime\nfastestLapSpeed\nstatusId\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10.0\n58\n1:34:50.616\n5690616\n39\n2\n1:27.452\n218.300\n1\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8.0\n58\n+5.478\n5696094\n41\n3\n1:27.739\n217.586\n1\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6.0\n58\n+8.163\n5698779\n41\n5\n1:28.090\n216.719\n1\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5.0\n58\n+17.181\n5707797\n58\n7\n1:28.603\n215.464\n1\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4.0\n58\n+18.014\n5708630\n43\n1\n1:27.418\n218.385\n1\n\n\n\n\n\n\n\n\nresults.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nresultId\n26080.0\n13041.372661\n7530.008377\n1.0\n6520.75\n13040.5\n19560.25\n26085.0\n\n\nraceId\n26080.0\n536.695667\n303.034639\n1.0\n294.75\n519.0\n791.00\n1110.0\n\n\ndriverId\n26080.0\n266.277569\n272.581622\n1.0\n57.00\n163.0\n364.00\n858.0\n\n\nconstructorId\n26080.0\n49.059663\n60.221056\n1.0\n6.00\n25.0\n58.25\n214.0\n\n\ngrid\n26080.0\n11.167561\n7.232797\n0.0\n5.00\n11.0\n17.00\n34.0\n\n\npositionOrder\n26080.0\n12.854141\n7.700068\n1.0\n6.00\n12.0\n18.00\n39.0\n\n\npoints\n26080.0\n1.906635\n4.219715\n0.0\n0.00\n0.0\n2.00\n50.0\n\n\nlaps\n26080.0\n46.076687\n29.726058\n0.0\n22.00\n53.0\n66.00\n200.0\n\n\nstatusId\n26080.0\n17.476074\n26.129965\n1.0\n1.00\n10.0\n14.00\n141.0\n\n\n\n\n\n\n\n\nresults = results.drop(labels = ['milliseconds'], axis = 1)\n\n\nresults['position'] = results['position'].replace(r'\\\\N', np.nan, regex = True)\nresults = results.dropna(subset = ['position'])\n\n\ndef convert_to_seconds(time_str):\n    try:\n        minutes, rest = time_str.split(\":\")\n        seconds, milliseconds = rest.split(\".\")\n        total_seconds = int(minutes)*60 + int(seconds) + int(milliseconds)/1000\n        return total_seconds\n    except ValueError:\n        return None\n\n# Apply the function to the column\nresults['fastestLapTime_seconds'] = results['fastestLapTime'].apply(convert_to_seconds)\nresults = results.dropna(subset = ['fastestLapSpeed'])\nresults\n\n\n\n\n\n\n\n\nresultId\nraceId\ndriverId\nconstructorId\nnumber\ngrid\nposition\npositionText\npositionOrder\npoints\nlaps\ntime\nfastestLap\nrank\nfastestLapTime\nfastestLapSpeed\nstatusId\nfastestLapTime_seconds\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10.0\n58\n1:34:50.616\n39\n2\n1:27.452\n218.300\n1\n87.452\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8.0\n58\n+5.478\n41\n3\n1:27.739\n217.586\n1\n87.739\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6.0\n58\n+8.163\n41\n5\n1:28.090\n216.719\n1\n88.090\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5.0\n58\n+17.181\n58\n7\n1:28.603\n215.464\n1\n88.603\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4.0\n58\n+18.014\n43\n1\n1:27.418\n218.385\n1\n87.418\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26073\n26079\n1110\n848\n3\n23\n15\n14\n14\n14\n0.0\n44\n+1:36.184\n35\n3\n1:49.841\n229.553\n1\n109.841\n\n\n26074\n26080\n1110\n825\n210\n20\n16\n15\n15\n15\n0.0\n44\n+1:41.754\n27\n14\n1:50.993\n227.171\n1\n110.993\n\n\n26075\n26081\n1110\n817\n213\n3\n19\n16\n16\n16\n0.0\n44\n+1:43.071\n25\n15\n1:50.994\n227.169\n1\n110.994\n\n\n26076\n26082\n1110\n858\n3\n2\n18\n17\n17\n17\n0.0\n44\n+1:44.476\n37\n9\n1:50.486\n228.213\n1\n110.486\n\n\n26077\n26083\n1110\n807\n210\n27\n0\n18\n18\n18\n0.0\n44\n+1:50.450\n26\n4\n1:49.907\n229.415\n1\n109.907\n\n\n\n\n15207 rows × 18 columns\n\n\n\n\nresults = results.dropna(subset=['fastestLapTime_seconds'])\n\n\nresults\n\n\n\n\n\n\n\n\nresultId\nraceId\ndriverId\nconstructorId\nnumber\ngrid\nposition\npositionText\npositionOrder\npoints\nlaps\ntime\nfastestLap\nrank\nfastestLapTime\nfastestLapSpeed\nstatusId\nfastestLapTime_seconds\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10.0\n58\n1:34:50.616\n39\n2\n1:27.452\n218.300\n1\n87.452\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8.0\n58\n+5.478\n41\n3\n1:27.739\n217.586\n1\n87.739\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6.0\n58\n+8.163\n41\n5\n1:28.090\n216.719\n1\n88.090\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5.0\n58\n+17.181\n58\n7\n1:28.603\n215.464\n1\n88.603\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4.0\n58\n+18.014\n43\n1\n1:27.418\n218.385\n1\n87.418\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26073\n26079\n1110\n848\n3\n23\n15\n14\n14\n14\n0.0\n44\n+1:36.184\n35\n3\n1:49.841\n229.553\n1\n109.841\n\n\n26074\n26080\n1110\n825\n210\n20\n16\n15\n15\n15\n0.0\n44\n+1:41.754\n27\n14\n1:50.993\n227.171\n1\n110.993\n\n\n26075\n26081\n1110\n817\n213\n3\n19\n16\n16\n16\n0.0\n44\n+1:43.071\n25\n15\n1:50.994\n227.169\n1\n110.994\n\n\n26076\n26082\n1110\n858\n3\n2\n18\n17\n17\n17\n0.0\n44\n+1:44.476\n37\n9\n1:50.486\n228.213\n1\n110.486\n\n\n26077\n26083\n1110\n807\n210\n27\n0\n18\n18\n18\n0.0\n44\n+1:50.450\n26\n4\n1:49.907\n229.415\n1\n109.907\n\n\n\n\n6438 rows × 18 columns\n\n\n\n\nresults.to_csv('cleanedResults.csv', index = False)\n\n\n\nCorrelation between dataset\n\n## we will start our preliminary analysis by finding the correlation bewteen dataset\n## the first step is to join certain dataset by their primary key to get a new result dataset\nmergedResults = pd.merge(results, races, left_on = 'raceId', right_index = True, how = 'left')\nmergedResults = pd.merge(mergedResults, circuits, left_on = 'circuitId', right_index = True, how = 'left')\nmergedResults = pd.merge(mergedResults, constructors, left_on = 'constructorId', right_index = True, how = 'left')\nmergedResults = pd.merge(mergedResults, drivers, left_on = 'driverId', right_index = True, how = 'left')\nmergedResults\n\n\n\n\n\n\n\n\nresultId\nraceId_x\ndriverId_x\nconstructorId_x\nnumber\ngrid\nposition\npositionText\npositionOrder\npoints\n...\nlat\nlng\nalt\nconstructorId_y\nconstructorRef\nconstructorName\nconstructorNationality\ndriverId_y\ndriverNationality\ndriverName\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10.0\n...\n26.0325\n50.5106\n7\n2.0\nbmw_sauber\nBMW Sauber\nGerman\n2.0\nGerman\nNick Heidfeld\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8.0\n...\n26.0325\n50.5106\n7\n3.0\nwilliams\nWilliams\nBritish\n3.0\nGerman\nNico Rosberg\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6.0\n...\n26.0325\n50.5106\n7\n4.0\nrenault\nRenault\nFrench\n4.0\nSpanish\nFernando Alonso\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5.0\n...\n26.0325\n50.5106\n7\n5.0\ntoro_rosso\nToro Rosso\nItalian\n5.0\nFinnish\nHeikki Kovalainen\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4.0\n...\n26.0325\n50.5106\n7\n2.0\nbmw_sauber\nBMW Sauber\nGerman\n6.0\nJapanese\nKazuki Nakajima\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26073\n26079\n1110\n848\n3\n23\n15\n14\n14\n14\n0.0\n...\nNaN\nNaN\nNaN\n4.0\nrenault\nRenault\nFrench\n850.0\nBrazilian\nPietro Fittipaldi\n\n\n26074\n26080\n1110\n825\n210\n20\n16\n15\n15\n15\n0.0\n...\nNaN\nNaN\nNaN\n214.0\nalpine\nAlpine F1 Team\nFrench\n826.0\nRussian\nDaniil Kvyat\n\n\n26075\n26081\n1110\n817\n213\n3\n19\n16\n16\n16\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n818.0\nFrench\nJean-Éric Vergne\n\n\n26076\n26082\n1110\n858\n3\n2\n18\n17\n17\n17\n0.0\n...\nNaN\nNaN\nNaN\n4.0\nrenault\nRenault\nFrench\nNaN\nNaN\nNaN\n\n\n26077\n26083\n1110\n807\n210\n27\n0\n18\n18\n18\n0.0\n...\nNaN\nNaN\nNaN\n214.0\nalpine\nAlpine F1 Team\nFrench\n807.0\nGerman\nNico Hülkenberg\n\n\n\n\n6438 rows × 40 columns\n\n\n\n\nmergedPitStops = pd.merge(pitStops,races, left_on = 'raceId', right_index = True, how = 'left')\nmergedPitStops = pd.merge(mergedPitStops,circuits, left_on = 'circuitId', right_index = True, how = 'left')\nmergedPitStops = pd.merge(mergedPitStops, mergedResults[['raceId_x', 'driverId_x', 'driverName', 'constructorId_x', 'constructorName']], left_on = ['raceId_x', 'driverId'], right_on = ['raceId_x', 'driverId_x'])\nmergedPitStops\n\n\n\n\n\n\n\n\nraceId_x\ndriverId\nstop\nlap\npitTime\nduration\nseconds\nraceId_y\nyear\nround\n...\ncircuitName\ncircuitLocation\ncircuitCountry\nlat\nlng\nalt\ndriverId_x\ndriverName\nconstructorId_x\nconstructorName\n\n\n\n\n0\n841\n153\n1\n1\n17:05:23\n26.898\n26.898\n843.0\n2011.0\n3.0\n...\nAutódromo José Carlos Pace\nSão Paulo\nBrazil\n-23.7036\n-46.6997\n785\n153\nRomain Grosjean\n5\nFerrari\n\n\n1\n841\n153\n2\n17\n17:31:06\n24.463\n24.463\n843.0\n2011.0\n3.0\n...\nAutódromo José Carlos Pace\nSão Paulo\nBrazil\n-23.7036\n-46.6997\n785\n153\nRomain Grosjean\n5\nFerrari\n\n\n2\n841\n153\n3\n35\n17:59:45\n26.348\n26.348\n843.0\n2011.0\n3.0\n...\nAutódromo José Carlos Pace\nSão Paulo\nBrazil\n-23.7036\n-46.6997\n785\n153\nRomain Grosjean\n5\nFerrari\n\n\n3\n841\n17\n1\n11\n17:20:48\n23.426\n23.426\n843.0\n2011.0\n3.0\n...\nAutódromo José Carlos Pace\nSão Paulo\nBrazil\n-23.7036\n-46.6997\n785\n17\nJenson Button\n9\nForce India\n\n\n4\n841\n17\n2\n26\n17:44:29\n22.520\n22.520\n843.0\n2011.0\n3.0\n...\nAutódromo José Carlos Pace\nSão Paulo\nBrazil\n-23.7036\n-46.6997\n785\n17\nJenson Button\n9\nForce India\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9218\n1110\n830\n1\n14\n15:30:04\n22.887\n22.887\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n830\nFelipe Nasr\n9\nForce India\n\n\n9219\n1110\n830\n2\n30\n16:00:16\n23.012\n23.012\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n830\nFelipe Nasr\n9\nForce India\n\n\n9220\n1110\n840\n1\n20\n15:42:12\n25.397\n25.397\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n840\nAntonio Giovinazzi\n117\nMoore\n\n\n9221\n1110\n847\n1\n22\n15:46:00\n23.837\n23.837\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n847\nNicholas Latifi\n131\nHWM\n\n\n9222\n1110\n842\n1\n23\n15:48:00\n25.664\n25.664\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n842\nCharles Leclerc\n214\nNaN\n\n\n\n\n9223 rows × 26 columns\n\n\n\n\nraceResults = pd.merge(mergedResults, mergedPitStops.groupby(by = ['raceId_x', 'raceName', 'constructorName', 'driverId', 'driverName']).sum(), left_on = ['raceId_x', 'driverId_x'], right_on = ['raceId_x', 'driverId'], how = 'left')\nraceResults\n\n/var/folders/j9/cbm31jzn08z95c3hz67rzjyc0000gn/T/ipykernel_47558/2923723585.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  raceResults = pd.merge(mergedResults, mergedPitStops.groupby(by = ['raceId_x', 'raceName', 'constructorName', 'driverId', 'driverName']).sum(), left_on = ['raceId_x', 'driverId_x'], right_on = ['raceId_x', 'driverId'], how = 'left')\n\n\n\n\n\n\n\n\n\nresultId\nraceId_x\ndriverId_x_x\nconstructorId_x_x\nnumber\ngrid\nposition\npositionText\npositionOrder\npoints\n...\nseconds\nraceId_y_y\nyear_y\nround_y\ncircuitId_x_y\ncircuitId_y_y\nlat_y\nlng_y\ndriverId_x_y\nconstructorId_x_y\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6433\n26079\n1110\n848\n3\n23\n15\n14\n14\n14\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6434\n26080\n1110\n825\n210\n20\n16\n15\n15\n15\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6435\n26081\n1110\n817\n213\n3\n19\n16\n16\n16\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6436\n26082\n1110\n858\n3\n2\n18\n17\n17\n17\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6437\n26083\n1110\n807\n210\n27\n0\n18\n18\n18\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n6438 rows × 52 columns\n\n\n\n\nWe have some variables naming issue that lots of variables are sharing the same variable name in different dataset when we try to merge datasets in the first time. Therefore, renaming variables in each dataset is necessary. The above code is actually the second time mergeing and since code of merging dataset are the same, only the second time merging process are displayed.\n\nfig = px.line(mergedPitStops[mergedPitStops['seconds'] &lt; 50].groupby(by = ['year', 'constructorName']).mean(numeric_only=True).reset_index(),\n                 x = 'year',\n                 y = 'seconds',\n                 color = 'constructorName'\n                )\nfig.update_layout(\n    title_text='Average Pit Stop Times by Constructor',\n)\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nfig = px.box(mergedPitStops[mergedPitStops['seconds'] &lt; 50].groupby(by = ['raceId_x', 'raceName', 'date', 'constructorName']).mean(numeric_only=True).reset_index().sort_values(by = 'seconds', ascending = True),\n                 x = 'constructorName',\n                 y = 'seconds',\n                 color = 'constructorName'\n                )\nfig.update_layout(\n    title_text='Pit Stop Durations by Constructor from 2011 to date',\n)\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\n\nOutlier\n\nQ1 = mergedResults.quantile(0.25)\nQ3 = mergedResults.quantile(0.25)\nIQR = Q3 - Q1\nmergedResults[~((mergedResults &lt; (Q1 - 1.5*IQR))| (mergedResults &gt; (Q3 + 1.5*IQR))).any(axis = 1)]\nmergedResults\n\n/var/folders/j9/cbm31jzn08z95c3hz67rzjyc0000gn/T/ipykernel_47558/1743655405.py:1: FutureWarning:\n\nThe default value of numeric_only in DataFrame.quantile is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n\n/var/folders/j9/cbm31jzn08z95c3hz67rzjyc0000gn/T/ipykernel_47558/1743655405.py:2: FutureWarning:\n\nThe default value of numeric_only in DataFrame.quantile is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n\n/var/folders/j9/cbm31jzn08z95c3hz67rzjyc0000gn/T/ipykernel_47558/1743655405.py:4: FutureWarning:\n\nAutomatic reindexing on DataFrame vs Series comparisons is deprecated and will raise ValueError in a future version. Do `left, right = left.align(right, axis=1, copy=False)` before e.g. `left == right`\n\n\n\n\n\n\n\n\n\n\nresultId\nraceId_x\ndriverId_x\nconstructorId_x\nnumber\ngrid\nposition\npositionText\npositionOrder\npoints\n...\nlat\nlng\nalt\nconstructorId_y\nconstructorRef\nconstructorName\nconstructorNationality\ndriverId_y\ndriverNationality\ndriverName\n\n\n\n\n0\n1\n18\n1\n1\n22\n1\n1\n1\n1\n10.0\n...\n26.0325\n50.5106\n7\n2.0\nbmw_sauber\nBMW Sauber\nGerman\n2.0\nGerman\nNick Heidfeld\n\n\n1\n2\n18\n2\n2\n3\n5\n2\n2\n2\n8.0\n...\n26.0325\n50.5106\n7\n3.0\nwilliams\nWilliams\nBritish\n3.0\nGerman\nNico Rosberg\n\n\n2\n3\n18\n3\n3\n7\n7\n3\n3\n3\n6.0\n...\n26.0325\n50.5106\n7\n4.0\nrenault\nRenault\nFrench\n4.0\nSpanish\nFernando Alonso\n\n\n3\n4\n18\n4\n4\n5\n11\n4\n4\n4\n5.0\n...\n26.0325\n50.5106\n7\n5.0\ntoro_rosso\nToro Rosso\nItalian\n5.0\nFinnish\nHeikki Kovalainen\n\n\n4\n5\n18\n5\n1\n23\n3\n5\n5\n5\n4.0\n...\n26.0325\n50.5106\n7\n2.0\nbmw_sauber\nBMW Sauber\nGerman\n6.0\nJapanese\nKazuki Nakajima\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n26073\n26079\n1110\n848\n3\n23\n15\n14\n14\n14\n0.0\n...\nNaN\nNaN\nNaN\n4.0\nrenault\nRenault\nFrench\n850.0\nBrazilian\nPietro Fittipaldi\n\n\n26074\n26080\n1110\n825\n210\n20\n16\n15\n15\n15\n0.0\n...\nNaN\nNaN\nNaN\n214.0\nalpine\nAlpine F1 Team\nFrench\n826.0\nRussian\nDaniil Kvyat\n\n\n26075\n26081\n1110\n817\n213\n3\n19\n16\n16\n16\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n818.0\nFrench\nJean-Éric Vergne\n\n\n26076\n26082\n1110\n858\n3\n2\n18\n17\n17\n17\n0.0\n...\nNaN\nNaN\nNaN\n4.0\nrenault\nRenault\nFrench\nNaN\nNaN\nNaN\n\n\n26077\n26083\n1110\n807\n210\n27\n0\n18\n18\n18\n0.0\n...\nNaN\nNaN\nNaN\n214.0\nalpine\nAlpine F1 Team\nFrench\n807.0\nGerman\nNico Hülkenberg\n\n\n\n\n6438 rows × 40 columns\n\n\n\n\nthere are no obvious outlier detected since no rows was removed\n\n\n\nHypothesis Refination\nWe car observe that there are some differences between every constructor’s pit stop time, however, those differences are within the range of 1 to 2 seconds which is quite insignificant even in the formula 1 race since there are many uncertainty in the race and any of those uncertainty could cause error more than 2 seconds\nTherefore, hypothesis of this project should divert to will the pit stop time differences have the effect of determine the winner of one race in the following project."
  },
  {
    "objectID": "Pages/Dimensionality Reduction.html",
    "href": "Pages/Dimensionality Reduction.html",
    "title": "Dimensionality Reduction",
    "section": "",
    "text": "Python: Programming language for implementing algorithms and data manipulation.\nscikit-learn: Machine learning library for PCA and t-SNE.\nmatplotlib and seaborn: Libraries for visualizing the results.\npandas: Library for data manipulation and analysis.\nNumPy: Library for numerical operations.\n\n\n## import necessary libraries \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.impute import SimpleImputer\n\n\nresults = pd.read_csv('Data/results.csv')\nmergedPitStops = pd.read_csv('Data/mergedPitStops.csv')\n\n\ndata = pd.merge(mergedPitStops,results[['driverId', 'position']], left_on = 'driverId', right_index = True, how = 'left')\n\n/var/folders/j9/cbm31jzn08z95c3hz67rzjyc0000gn/T/ipykernel_47670/367688774.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {'driverId_x'} in the result is deprecated and will raise a MergeError in a future version.\n  data = pd.merge(mergedPitStops,results[['driverId', 'position']], left_on = 'driverId', right_index = True, how = 'left')\n\n\n\ncolumn_to_move = data.pop('position')\ndata.insert(2, 'position', column_to_move)\ndata = data.replace('\\\\N', pd.NA)\ndata = data.dropna()"
  },
  {
    "objectID": "Pages/Dimensionality Reduction.html#try-with-different-perplexity",
    "href": "Pages/Dimensionality Reduction.html#try-with-different-perplexity",
    "title": "Dimensionality Reduction",
    "section": "Try with different perplexity",
    "text": "Try with different perplexity\n\n# Applying t-SNE\ntsne1 = TSNE(n_components = 2, perplexity = 15, n_iter = 300)\ntsne_results1 = tsne1.fit_transform(scaled_data)\n\n# Visualization\nplt.figure(figsize = (12,8))\nplt.scatter(tsne_results1[:, 0], tsne_results1[:, 1])\nplt.xlabel('TSNE Component 1')\nplt.ylabel('TSNE Component 2')\nplt.title('t-SNE visualization of the dataset')\nplt.show()\n\n\n\n\nAt a lower perplexity, t-SNE tends to focus on local structure, which could mean that clusters appear more compact or dense if the local groupings in the high-dimensional space are strong.\nLower perplexity might also lead to less overlap between clusters, as the algorithm pays more attention to the local neighbors of each point. However, if the perplexity is too low, t-SNE might start to fragment clusters that actually belong together, leading to a representation with many small, separate clusters that do not necessarily reflect meaningful groupings."
  },
  {
    "objectID": "Pages/Conclusion.html",
    "href": "Pages/Conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "Overview\nIn my project, I conducted a comprehensive analysis of Formula 1 pit stops with the aim of revealing the complexity and strategic importance of these critical moments in the race. My research focuses on a number of aspects such as pit stop duration, relevance to teams and circuits, and overall impact on race strategy.\n\n\nResearch Methodology.\nWhile collecting data through Python and R APIs, I encountered difficulties with data formatting and extraction. After overcoming these difficulties, I managed to collect a robust dataset for analysis. I chose the Naive Bayes classification method because it is suitable for large datasets and assumes that the variables are independent of each other, which is an important factor considering the multifaceted nature of F1 data.\n\n\nQuestions planed to answer:\n\nHow did pit stop duration change over time?\n\nThe overall pit stop duration would be approximately the same over time for one team in a race. Actions would cause increasing pit stop duration would be human error made by the driver or the team engineerings.\n\nIs there a relationship between pit stop durations and constructor/team?\n\nYes, observation in the EDA shows that there is a relationship between pit stop durations and constructors. Although it remains a weak relationship, still prove that there is a slight relation.\n\nIs there a relationship between pit stop durations and race circuit?\n\nNo, there is no obvious relationship between pit stop durations and race circuit since they pit stop durations are mostly depend on the driver and engineerings which would be perform consistantly in all race except some occasionally mistakes. Therefore, pit stop durations is not related to race circuit.\n\nWhat is the time spent in the pit lane as a percentage of the race for a driver?\n\nAverage pit stop duration in the pit lane for all race circuits is about 26 seconds and each driver do a 1.5 times pit stops in a race, and the mean race time for all race circuits is approaximately 6000 seconds. Therefore, time spent in the pit lance as a percentage of the race for a driver would be 0.65%.\n\nWho is the best constructor on pit stop performance?\n\nThe overall best constructor on pit stop performance in term of pit stop durations would be the Red Bull Racing.\n\nDoes the pit stop time affect the race?\n\nDefinitely yes, the pit stop durations would directly affects the race strategies for the team and usually a shorter pit stop duration would give more flexible time window for the next pit stop or sometimes undercut the rival.\n\nWhat is the lap number that most car choose to pit stop?\n\nThe lap number that most car choose to pit stop is actually dynamic. Pit stop timing need to be carefully designed before the race since each circuit is unique and have different time window for pit stop, however, there will always have troubles like accidents, safety cars, or even red flags that recalls all the cars back. Therefore, there is no obvious lap number that most car choose to pit stop, but the lap number to pit stop is a normal distribution that usually centered on the half of the overall lap numbers for a circuits.\n\nIs car doing more pit stops have advantages on those who do less pit stops?\n\nTechnically yes, but different car have different performance on the same formula or tire. Softer tire have more friction but also easier to be wore out. Alfa Romeo team this season had awful performance using soft and medium tire compare to other teams, but their performance on hard tire would out-perform others a lot which is quite strange to see. Back to the question, pit stop is dependent on the team performance on tire, which is unimagable difficult for me to do a thorough analysis on it.\n\nWho have the fastest pit stop and did he get championship that year?\n\nCurrent fastest pit stop was made during lap 27 of Qatar Grand Prix by Lando Norris from McLaren in the 2023 season. However, he did not get the World Driver Champion this year.\n\nIs the pit stop time consistent with driver’s lap time?\n\nThere is clear relationship between pit stop time and driver’s lap time.\n\n\n\n\nKey findings and analysis\nMy exploratory data analysis yielded several noteworthy insights: * Pit stop duration over time: + I observed that pit stop duration remained relatively consistent across teams, which was largely influenced by human factors.\n\nTeam-Manufacturer Relationship:\n\nMy analysis revealed a weak but significant relationship between pit stop duration and team.\n\nTrack influence:\n\nInterestingly, I did not find a substantial correlation between pit stop duration and track, suggesting that team performance and individual driver skills are more dependent on pit stop duration.\n\nPit stop time:\n\nThe analysis shows that the time spent in the pits is only a small fraction of the total race time, which emphasizes the efficiency of the pit crew.\n\nBEST TEAM PERFORMANCE:\n\nRed Bull Racing stood out in my findings in terms of pit stop performance.\n\nImpact of pit stops:\n\nI found that the timing and frequency of pit stops was strategically crucial and had a clear impact on race results.\n\nPit stop frequency and advantage:\n\nThe results of this study suggest that more frequent pit stops can lead to a tactical advantage, although this depends on a number of factors including tire performance and team strategy.\n\n\n\n\nLimitations and Challenges\nI encountered a number of limitations in my project: * Data Selection and Quality: + Relying on a cleaned dataset may have limited the scope of my analysis.\n\nModel Selection and Assumptions:\n\nAlthough Naive Bayes models are robust, their assumptions of feature independence may not fully capture the complex interdependencies in F1 racing data.\n\nVariable Relationships:\n\nThe lack of clear relationships between certain variables and race results suggests that there may be gaps in the data or a need for more detailed modeling techniques.\n\n\n\n\nFuture Directions and Improvements\nLooking ahead, there are several ways to enhance the analysis: * Expanding data sources: + Incorporating more data sets, including real-time race data and more granular team and driver statistics, could enrich the analysis.\n\nAdvanced modeling techniques:\n\nExploring machine learning models that take more account of the interdependence of variables may yield more accurate predictions and insights.\n\nDeeper analysis of teams and drivers:\n\nFocusing on individual teams or drivers over multiple seasons can reveal specific strategies or performance patterns related to pit stops.\n\nInteractive and real-time analytics:\n\nDeveloping a model that provides real-time insights during a race could be a breakthrough application of my work.\n\nBroader strategic context:\n\nIntegrating my findings with broader race strategies could provide a more holistic view of race planning and execution.\n\n\n\n\nConclusion.\nMy project has made an important contribution to understanding the nuances of pit strategy in Formula One. It has provided valuable insights into the factors influencing pit stop efficiency and their impact on race outcomes, while also highlighting the complexity and multifaceted nature of this aspect of F1 racing. Future research will build on my fundamental work and has the potential to further reveal the intricate balance of speed, strategy and precision that characterizes the world of Formula 1 racing."
  },
  {
    "objectID": "Pages/Naive Bayes.html",
    "href": "Pages/Naive Bayes.html",
    "title": "Introduction of Naive Bayes",
    "section": "",
    "text": "What is Naive Bayes classification Naive Bayes is a classification algorithm based on Bayes’ theorem, which is a fundamental theorem in probability theory. It being called Naive is because it assumes that each input variable is independent. This is a strong assumption and unrealistic for real data; however, the technique is very effective on a large range of complex problems.\nHow is Naive Bayes classification works 1. Model traning During the training phase, the algorithm calculates the probabilities of the different classes in the training data (the prior probabilities). It also calculates the conditional probabilities of each feature given the class.\n\nAssumption of Independence: Naive Bayes assumes that the features are independent given the class. This means that the presence of a particular feature does not affect the presence of any other feature, as long as the class is known.\nMaking Predictions: To make a prediction for a new data point, the algorithm calculates the posterior probability for each class, using Bayes’ theorem. The class with the highest posterior probability is the output prediction.\n\nThe probabilistic nature of Naive Bayes The algorithm uses the probabilities calculated from the training data to make predictions on new, unseen data. Hereâ€™s how it works:\n\nCalculate Prior Probabilities: It starts by calculating the prior probabilities of each class in the training data, P(A)\nCalculate Likelihoods: It calculates the likelihood of each feature given each class, P(B|A)\nAssume Feature Independence: Naive Bayes assumes that the features are independent given the class. This means that the presence of one feature does not affect the presence of another, as long as we know the class.\nCalculate Posterior Probabilities: For a new data point, it uses Bayesâ€™ theorem to calculate the posterior probability of each class given the observed features, P(A|B)\nMake Prediction: The class with the highest posterior probability is the predicted class.\n\nBayes’ thorem foundation The foundation of Bayes’ theorem lies in conditional probability. It provides a way to revise existing predictions or theories (priors) given new evidence. In the context of statistics and machine learning, this is especially powerful as it provides a framework for updating probabilities when new data is observed.\nDifferent variants of Naive Bayes and when to use each 1. Gaussian Naive Bayes: Assumes that the continuous values associated with each class are distributed according to a Gaussian (normal) distribution. Use Gaussian Naive Bayes when your features are continuous and you can assume a Gaussian distribution. This is commonly used in problems like text classification where features are related to word frequencies or other count data.\n\nMultinomial Naive Bayes: Assumes that features represent counts or frequency of occurrence of an event. The value of the feature is the count of the number of times a particular event or value has occurred. Use Multinomial Naive Bayes for discrete data. Itâ€™s particularly well-suited for text classification problems, such as spam filtering and sentiment analysis, where the features are word frequencies or counts.\nBernoulli Naive Bayes: Assumes that all features are binary (i.e., they take only two values). The parameters that Bernoulli Naive Bayes models is the probability of each feature being equal to 1 for each class. Use Bernoulli Naive Bayes when your features are binary. Like Multinomial Naive Bayes, it is also used for text data but it models binary/boolean features.\n\nDefine the objectives of trying to do To predict the category of new, unseen data by applying probabilistic measures learned from the training dataset.\nThe aim to achieve through Naive Bayes classification The primary aim of using the Naive Bayes classification is to create a model that can be used to provide reliable prediction on future dataset."
  },
  {
    "objectID": "Pages/Data Cleaning.html",
    "href": "Pages/Data Cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "The data cleaning process use Python: https://github.com/anly501/dsan-5000-project-VaBrox/blob/main/codes/01-data-gathering/pythonClean.py\nI used the CountVectorizer to predict the duration of pit stop time by the lap they pit. The outcome shows that there is no obvious relation between the duration of pit stop time and the lap they pit. So this cleaning helps me exclude a variable that can not affect the pit stop time in the future reseach.\nThe data cleaning process use R https://github.com/anly501/dsan-5000-project-VaBrox/blob/main/codes/01-data-gathering/rClean.R\nThis data set provide compresive infomation about each race status. The only cleaning I can do on this data set is to elimante some possible NA values and select certain variables I need for my analysis on the pit stop time duration."
  },
  {
    "objectID": "Pages/Data.html",
    "href": "Pages/Data.html",
    "title": "All data used for this project",
    "section": "",
    "text": "The raw data sources: https://docs.google.com/spreadsheets/d/1UmrM2zPuqpjiYYvR1XnglQnoP_QI2tyDMA5Eaz99Q1w/edit#gid=0\nhttp://ergast.com/api/f1/2020/5/pitstops"
  }
]